import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

# Konfiguracja
plt.rcParams['figure.figsize'] = (14, 8)
plt.rcParams['font.size'] = 10
sns.set_palette("husl")

# Wczytanie danych
df = pd.read_csv('experiment_results.csv')

# Utworzenie folderu na wyniki
output_dir = Path('outputs/analysis')
output_dir.mkdir(parents=True, exist_ok=True)

print("=" * 80)
print("ANALIZA STABILNO≈öCI EKSPERYMENT√ìW - ALGORYTMY GENETYCZNE TSP")
print("=" * 80)

# ============================================================================
# 1. STATYSTYKI PODSTAWOWE DLA KA≈ªDEGO EKSPERYMENTU
# ============================================================================

print("\n" + "=" * 80)
print("1. STABILNO≈öƒÜ KA≈ªDEGO EKSPERYMENTU")
print("=" * 80)

stability_stats = df.groupby('experiment_name').agg({
    'best_distance': ['count', 'mean', 'std', 'min', 'max'],
    'generations_completed': ['mean', 'std']
}).round(2)

stability_stats.columns = ['_'.join(col).strip() for col in stability_stats.columns]
stability_stats['cv_distance'] = (stability_stats['best_distance_std'] /
                                  stability_stats['best_distance_mean'] * 100).round(2)

# Sortowanie po wsp√≥≈Çczynniku zmienno≈õci (od najbardziej stabilnego)
stability_stats = stability_stats.sort_values('cv_distance')

print("\nWsp√≥≈Çczynnik Zmienno≈õci (CV) - im ni≈ºszy, tym bardziej stabilny eksperyment:")
print(stability_stats[['best_distance_count', 'best_distance_mean', 'best_distance_std',
                       'best_distance_min', 'best_distance_max', 'cv_distance']])

# Zapisz do CSV
stability_stats.to_csv(output_dir / 'stability_summary.csv')
print(f"\n‚úì Zapisano szczeg√≥≈Çowe statystyki do: {output_dir / 'stability_summary.csv'}")

# ============================================================================
# 2. ANALIZA METOD SELEKCJI
# ============================================================================

print("\n" + "=" * 80)
print("2. POR√ìWNANIE METOD SELEKCJI RODZIC√ìW")
print("=" * 80)

selection_stats = df.groupby('parent_selection_type').agg({
    'best_distance': ['count', 'mean', 'std', 'min', 'max']
}).round(2)

selection_stats.columns = ['_'.join(col).strip() for col in selection_stats.columns]
selection_stats['cv'] = (selection_stats['best_distance_std'] /
                         selection_stats['best_distance_mean'] * 100).round(2)

print("\nMetody selekcji (sortowane po ≈õredniej jako≈õci):")
print(selection_stats.sort_values('best_distance_mean'))

# ============================================================================
# 3. WIZUALIZACJE
# ============================================================================

print("\n" + "=" * 80)
print("3. GENEROWANIE WIZUALIZACJI")
print("=" * 80)

# 3.1 BOXPLOT - Por√≥wnanie wszystkich eksperyment√≥w
fig, ax = plt.subplots(figsize=(16, 10))
df_sorted = df.sort_values('best_distance', ascending=False)
exp_order = df.groupby('experiment_name')['best_distance'].median().sort_values().index

sns.boxplot(data=df, y='experiment_name', x='best_distance',
            order=exp_order, ax=ax)
ax.set_xlabel('D≈Çugo≈õƒá trasy (best_distance)', fontsize=12, fontweight='bold')
ax.set_ylabel('Eksperyment', fontsize=12, fontweight='bold')
ax.set_title('Por√≥wnanie stabilno≈õci eksperyment√≥w - Boxplot\n(sortowane po medianie)',
             fontsize=14, fontweight='bold', pad=20)
ax.grid(axis='x', alpha=0.3)

# Dodaj adnotacje z liczbƒÖ pr√≥b
for i, exp in enumerate(exp_order):
    count = df[df['experiment_name'] == exp].shape[0]
    median = df[df['experiment_name'] == exp]['best_distance'].median()
    ax.text(median, i, f' n={count}', va='center', fontsize=9,
            bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.3))

plt.tight_layout()
plt.savefig(output_dir / 'boxplot_comparison.png', dpi=300, bbox_inches='tight')
print(f"‚úì Zapisano: {output_dir / 'boxplot_comparison.png'}")
plt.close()

# 3.2 SCATTER PLOT - Stabilno≈õƒá vs Jako≈õƒá
fig, ax = plt.subplots(figsize=(12, 8))

exp_summary = df.groupby('experiment_name').agg({
    'best_distance': ['mean', 'std', 'count']
}).reset_index()
exp_summary.columns = ['experiment_name', 'mean_distance', 'std_distance', 'count']

scatter = ax.scatter(exp_summary['mean_distance'], exp_summary['std_distance'],
                     s=exp_summary['count'] * 50, alpha=0.6, c=range(len(exp_summary)),
                     cmap='viridis', edgecolors='black', linewidth=1.5)

# Adnotacje
for idx, row in exp_summary.iterrows():
    ax.annotate(row['experiment_name'],
                (row['mean_distance'], row['std_distance']),
                xytext=(5, 5), textcoords='offset points',
                fontsize=8, alpha=0.8,
                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))

ax.set_xlabel('≈örednia d≈Çugo≈õƒá trasy (ni≈ºsza = lepiej)', fontsize=12, fontweight='bold')
ax.set_ylabel('Odchylenie standardowe (ni≈ºsze = stabilniej)', fontsize=12, fontweight='bold')
ax.set_title('Stabilno≈õƒá vs Jako≈õƒá eksperyment√≥w\n(rozmiar punktu = liczba uruchomie≈Ñ)',
             fontsize=14, fontweight='bold', pad=20)
ax.grid(alpha=0.3)

# Linie pomocnicze
ax.axhline(exp_summary['std_distance'].mean(), color='red', linestyle='--',
           alpha=0.5, label=f'≈örednie std: {exp_summary["std_distance"].mean():.1f}')
ax.axvline(exp_summary['mean_distance'].mean(), color='blue', linestyle='--',
           alpha=0.5, label=f'≈örednia mean: {exp_summary["mean_distance"].mean():.1f}')
ax.legend()

plt.tight_layout()
plt.savefig(output_dir / 'stability_vs_quality.png', dpi=300, bbox_inches='tight')
print(f"‚úì Zapisano: {output_dir / 'stability_vs_quality.png'}")
plt.close()

# 3.3 HISTOGRAMY dla ka≈ºdego eksperymentu
experiments = df['experiment_name'].unique()
n_exp = len(experiments)
n_cols = 3
n_rows = (n_exp + n_cols - 1) // n_cols

fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, n_rows * 4))
axes = axes.flatten() if n_exp > 1 else [axes]

for idx, exp in enumerate(sorted(experiments)):
    exp_data = df[df['experiment_name'] == exp]['best_distance']

    axes[idx].hist(exp_data, bins=min(20, len(exp_data)),
                   alpha=0.7, color='steelblue', edgecolor='black')
    axes[idx].axvline(exp_data.mean(), color='red', linestyle='--',
                      linewidth=2, label=f'≈örednia: {exp_data.mean():.1f}')
    axes[idx].axvline(exp_data.median(), color='green', linestyle='--',
                      linewidth=2, label=f'Mediana: {exp_data.median():.1f}')

    axes[idx].set_title(f'{exp}\n(n={len(exp_data)}, std={exp_data.std():.1f})',
                        fontweight='bold')
    axes[idx].set_xlabel('D≈Çugo≈õƒá trasy')
    axes[idx].set_ylabel('Czƒôsto≈õƒá')
    axes[idx].legend(fontsize=8)
    axes[idx].grid(alpha=0.3)

# Ukryj puste subploty
for idx in range(n_exp, len(axes)):
    axes[idx].set_visible(False)

plt.suptitle('Rozk≈Çad wynik√≥w dla ka≈ºdego eksperymentu',
             fontsize=16, fontweight='bold', y=1.00)
plt.tight_layout()
plt.savefig(output_dir / 'histograms_all.png', dpi=300, bbox_inches='tight')
print(f"‚úì Zapisano: {output_dir / 'histograms_all.png'}")
plt.close()


# ============================================================================
# 4. WNIOSKI I REKOMENDACJE
# ============================================================================

print("\n" + "=" * 80)
print("4. WNIOSKI I REKOMENDACJE")
print("=" * 80)

# Najlepsze konfiguracje
best_mean = stability_stats.nsmallest(3, 'best_distance_mean')
most_stable = stability_stats.nsmallest(3, 'cv_distance')
least_stable = stability_stats.nlargest(3, 'cv_distance')

print("\nüèÜ TOP 3 - NAJLEPSZE ≈öREDNIE WYNIKI (najmniejsza trasa):")
for idx, (exp_name, row) in enumerate(best_mean.iterrows(), 1):
    print(f"{idx}. {exp_name}: {row['best_distance_mean']:.2f} (¬±{row['best_distance_std']:.2f})")

print("\n‚úÖ TOP 3 - NAJSTABILNIEJSZE (najmniejszy CV):")
for idx, (exp_name, row) in enumerate(most_stable.iterrows(), 1):
    print(f"{idx}. {exp_name}: CV={row['cv_distance']:.2f}% (mean={row['best_distance_mean']:.2f})")

print("\n‚ö†Ô∏è  TOP 3 - NAJBARDZIEJ NIESTABILNE (najwiƒôkszy CV):")
for idx, (exp_name, row) in enumerate(least_stable.iterrows(), 1):
    print(f"{idx}. {exp_name}: CV={row['cv_distance']:.2f}% (mean={row['best_distance_mean']:.2f})")

# Diagnostyka niestabilno≈õci
print("\n" + "=" * 80)
print("DIAGNOSTYKA NIESTABILNO≈öCI")
print("=" * 80)

# Sprawd≈∫ czy niekt√≥re eksperymenty majƒÖ ma≈Ço pr√≥b
low_samples = stability_stats[stability_stats['best_distance_count'] < 5]
if len(low_samples) > 0:
    print(f"\n‚ö†Ô∏è  Eksperymenty z ma≈ÇƒÖ liczbƒÖ pr√≥b (< 5):")
    for exp_name, row in low_samples.iterrows():
        print(f"   - {exp_name}: tylko {int(row['best_distance_count'])} pr√≥b")
else:
    print("\n‚úì Wszystkie eksperymenty majƒÖ wystarczajƒÖcƒÖ liczbƒô pr√≥b")

# Sprawd≈∫ czy sƒÖ du≈ºe r√≥≈ºnice w liczbie generacji
gen_stats = df.groupby('experiment_name')['generations_completed'].agg(['mean', 'std', 'min', 'max'])
high_gen_variance = gen_stats[gen_stats['std'] > gen_stats['mean'] * 0.3]
if len(high_gen_variance) > 0:
    print(f"\n‚ö†Ô∏è  Eksperymenty z du≈ºƒÖ zmienno≈õciƒÖ liczby generacji:")
    for exp_name, row in high_gen_variance.iterrows():
        print(
            f"   - {exp_name}: {row['mean']:.0f} ¬±{row['std']:.0f} generacji (range: {int(row['min'])}-{int(row['max'])})")
else:
    print("\n‚úì Liczba generacji jest stabilna we wszystkich eksperymentach")

# Rekomendacje
print("\n" + "=" * 80)
print("üìã REKOMENDACJE:")
print("=" * 80)

avg_cv = stability_stats['cv_distance'].mean()
if avg_cv > 10:
    print(f"\n1. ≈öredni CV = {avg_cv:.1f}% - wyniki sƒÖ BARDZO NIESTABILNE")
    print("   Rozwa≈º:")
    print("   - Zwiƒôkszenie liczby uruchomie≈Ñ ka≈ºdego eksperymentu (min. 30 powt√≥rze≈Ñ)")
    print("   - Ustalenie sta≈Çego seed dla generatora liczb losowych")
    print("   - Wyd≈Çu≈ºenie czasu dzia≈Çania algorytmu (wiƒôcej generacji)")
elif avg_cv > 5:
    print(f"\n1. ≈öredni CV = {avg_cv:.1f}% - wyniki sƒÖ UMIARKOWANIE NIESTABILNE")
    print("   Rozwa≈º:")
    print("   - Zwiƒôkszenie liczby powt√≥rze≈Ñ do min. 20-30")
    print("   - Weryfikacjƒô czy parametry sƒÖ odpowiednie dla problemu")
else:
    print(f"\n1. ≈öredni CV = {avg_cv:.1f}% - wyniki sƒÖ wzglƒôdnie STABILNE")

print(f"\n2. Aby poprawiƒá por√≥wnywalno≈õƒá:")
print("   - Upewnij siƒô, ≈ºe ka≈ºdy eksperyment ma takƒÖ samƒÖ liczbƒô uruchomie≈Ñ")
print("   - U≈ºywaj tego samego zestawu instancji TSP dla wszystkich eksperyment√≥w")
print("   - Zapisuj wiƒôcej metryk (czas wykonania, r√≥≈ºnorodno≈õƒá populacji)")

print("\n" + "=" * 80)
print("‚úì ANALIZA ZAKO≈ÉCZONA")
print(f"‚úì Wszystkie wyniki zapisane w: {output_dir.absolute()}")
print("=" * 80)